---
layout: single
title: "LLM, RAG, VectorStore, Chunking, Token, 색인(Indexing) 핵심 용어 정리"
excerpt: "AI 기술 블로그 포스팅에 자주 등장하는 LLM, RAG, VectorStore, Chunking, Token, 색인(Indexing)에 대한 핵심 개념을 이해하기 쉽게 설명합니다."
categories: [AI, NLP]
tag: [LLM, RAG, VectorStore, Chunking, Token, Indexing]
toc: true
author_profile: false
sidebar:
    nav: "docs"

search: true
---

최근 생성형 AI의 발전과 함께 여러 용어들이 자주 등장하고 있습니다. 특히 기술 블로그나 논문에서 자주 언급되는 **LLM**, **RAG**, **VectorStore**, **Chunking**, **Token**, **색인(Indexing)** 과 같은 용어는 기술을 이해하고 실제 응용할 때 반드시 이해해야 하는 중요한 개념들입니다.

이 포스팅에서는 각 용어의 개념과 역할에 대해 최대한 간결하고 쉽게 설명합니다.

---

## 1. LLM (Large Language Model)

**LLM(Large Language Model)**은 대규모 데이터를 통해 학습된 인공지능 언어 모델입니다. 대표적으로 OpenAI의 GPT 시리즈가 있으며, 인간과 유사한 자연스러운 텍스트 생성 및 이해가 가능한 것이 특징입니다. 주로 질의응답, 글쓰기, 번역, 요약 등의 작업을 수행할 때 사용됩니다.

- **예시 모델**: GPT-3.5, GPT-4, LLaMA 등
- **사용 사례**: ChatGPT와 같은 챗봇, 자동 글 작성, 번역 및 요약 서비스

---

## 2. RAG (Retrieval-Augmented Generation)

**RAG(Retrieval-Augmented Generation)**은 정보 검색(검색 또는 Retrieval)과 텍스트 생성(Generation)을 결합한 방법론입니다. 즉, 외부 데이터베이스나 지식베이스에서 관련된 정보를 검색한 후, 이를 기반으로 질문에 대한 응답을 생성합니다. 이를 통해 LLM이 학습되지 않은 최신 정보 또는 구체적인 전문 지식을 제공할 수 있습니다.

- **장점**:
  - 실시간 정보 제공 가능
  - 최신 정보 반영 및 신뢰성 향상
- **사용 사례**: 문서 기반 챗봇, 고객 상담 서비스, 전문 지식이 요구되는 서비스

---

## 3. VectorStore (벡터 저장소)

**VectorStore(벡터 저장소)**는 텍스트 데이터를 숫자 형태의 벡터로 변환하여 저장하고, 효율적으로 검색하기 위한 데이터베이스입니다. 자연어로 이루어진 데이터는 그대로는 검색하기 어렵기 때문에 벡터로 변환하여 의미 기반의 검색이 가능합니다.

- **대표적인 기술**: FAISS, Pinecone, Chroma, Weaviate
- **장점**:
  - 빠르고 효율적인 의미 기반 검색
  - 높은 확장성과 성능
- **사용 사례**: 유사 문장 검색, 추천 시스템, RAG 기반 질의응답 시스템

---

## 4. Chunking (청킹, 텍스트 분할)

**Chunking(청킹)**은 긴 텍스트 데이터를 일정한 크기의 작은 덩어리로 나누는 과정입니다. LLM은 입력 길이에 한계(Token 제한)가 있으므로 긴 문서를 작은 청크로 분할해 효율적으로 처리합니다. 

- **Chunk 크기 선정 기준**:
  - LLM의 최대 입력 길이(Token) 제한 고려
  - 정보의 맥락과 문맥 유지
- **사용 사례**: 문서 요약, 정보 검색(RAG) 시스템 구축

---

## 5. Token (토큰)

**Token(토큰)**은 텍스트를 처리할 때의 최소 단위입니다. 영어의 경우 단어나 글자 단위가 되기도 하고, 한국어의 경우 형태소 또는 음절 단위로 나눌 수 있습니다. LLM은 입력 데이터를 Token 형태로 변환한 후 이를 바탕으로 연산을 수행합니다.

- **특징**:
  - 보통 하나의 단어나 공백, 기호 등으로 구성
  - LLM에서는 보통 1,000 토큰이 약 750 단어에 해당 (영어 기준)
- **사용 사례**: 자연어 처리 모델의 입력 단위, 문서 크기 제한 관리

---

## 6. 색인 (Indexing)

**색인(Indexing)**이란 문서 또는 데이터의 내용을 빠르게 검색할 수 있도록 미리 정리하고 구조화하는 과정을 의미합니다. 검색 엔진에서 흔히 사용되는 개념으로, 데이터가 많아질수록 필수적으로 수행되는 작업입니다.

- **특징**:
  - 빠른 검색 속도 보장
  - 효율적인 데이터 접근 가능
- **사용 사례**: 검색 엔진, 문서 검색 시스템, RAG 시스템의 Retrieval 단계

---

## 마치며

AI 및 NLP 관련 프로젝트를 진행할 때 자주 접하는 위의 용어들을 명확히 이해하면 시스템 설계 및 구현 과정에서 더 나은 의사결정을 내릴 수 있습니다. 특히, RAG와 같은 시스템을 구축하려면 LLM과 VectorStore, Chunking, Indexing의 연계 과정이 중요하므로, 각 요소의 역할과 특성을 잘 이해하고 있어야 합니다.

이 포스트가 기술 블로그를 시작하거나 관련 프로젝트를 수행할 때 조금이라도 도움이 되길 바랍니다.